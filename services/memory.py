# services/memory.py
import json
import os
from datetime import datetime

# Path to the local storage on the 1TB hard drive (simulated for sandbox)
MEMORY_FILE = "/home/ubuntu/my-ai-bot/user_memory.json"
MAX_MESSAGES = 10

def load_memory():
    """Loads user memory from the local JSON file."""
    if not os.path.exists(MEMORY_FILE):
        return {}
    try:
        with open(MEMORY_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception:
        return {}

def save_memory(memory):
    """Saves user memory to the local JSON file."""
    try:
        with open(MEMORY_FILE, 'w', encoding='utf-8') as f:
            json.dump(memory, f, indent=4, ensure_ascii=False)
    except Exception as e:
        print(f"Error saving memory: {e}")

def add_to_memory(user_id, role, text):
    """Adds a message to the user's conversation history."""
    memory = load_memory()
    user_id_str = str(user_id)
    
    if user_id_str not in memory:
        memory[user_id_str] = {"history": [], "personality": "Ù†Ø§Ù…Ø´Ø®Øµ"}
        
    # Add new message
    new_entry = {
        "role": role,
        "text": text,
        "timestamp": datetime.now().isoformat()
    }
    memory[user_id_str]["history"].append(new_entry)
    
    # Keep only the last MAX_MESSAGES
    memory[user_id_str]["history"] = memory[user_id_str]["history"][-MAX_MESSAGES:]
    
    save_memory(memory)

def get_history(user_id):
    """Retrieves the conversation history for a user."""
    memory = load_memory()
    user_id_str = str(user_id)
    
    if user_id_str in memory:
        # Format history for use by the LLM (e.g., Gemini)
        formatted_history = []
        for entry in memory[user_id_str]["history"]:
            formatted_history.append(f"[{entry['role']}]: {entry['text']}")
        return "\n".join(formatted_history)
    
    return ""

def get_personality(user_id):
    """Retrieves the user's analyzed personality."""
    memory = load_memory()
    user_id_str = str(user_id)
    
    return memory.get(user_id_str, {}).get("personality", "Ù†Ø§Ù…Ø´Ø®Øµ")

def update_personality(user_id, new_personality):
    """Updates the user's analyzed personality."""
    memory = load_memory()
    user_id_str = str(user_id)
    
    if user_id_str not in memory:
        memory[user_id_str] = {"history": [], "personality": "Ù†Ø§Ù…Ø´Ø®Øµ"}
        
    memory[user_id_str]["personality"] = new_personality
    save_memory(memory)
    
    return f"âœ… ØªØ­Ù„ÛŒÙ„ Ø´Ø®ØµÛŒØª Ú©Ø§Ø±Ø¨Ø± {user_id} Ø¨Ù‡ '{new_personality}' Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø´Ø¯."

def handle_personality_analysis(user_id):
    """Simulates a detailed personality analysis based on history."""
    history = get_history(user_id)
    
    if not history:
        return "âŒ Ø³Ø§Ø¨Ù‚Ù‡ Ù…Ú©Ø§Ù„Ù…Ù‡ Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø´Ø®ØµÛŒØª ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯."
    
    # In a real application, this would call Gemini with the history to perform analysis.
    # For now, we simulate a result based on the user's ID.
    
    if str(user_id) == "33230000":
        personality = "Ù¾Ø§Ø¯Ø´Ø§Ù‡ØŒ Ú©Ø§Ø±Ø¢ÙØ±ÛŒÙ†ØŒ Ùˆ Ø¹Ù„Ø§Ù‚Ù‡â€ŒÙ…Ù†Ø¯ Ø¨Ù‡ Ø³Ø®Øªâ€ŒØ§ÙØ²Ø§Ø± Ùˆ ØªØ±ÛŒØ¯"
    else:
        personality = "Ú©Ø§Ø±Ø¨Ø± Ø¹Ø§Ø¯ÛŒØŒ Ù…Ø­ØªØ§Ø·ØŒ Ùˆ Ø¹Ù„Ø§Ù‚Ù‡â€ŒÙ…Ù†Ø¯ Ø¨Ù‡ Ø¢Ù…ÙˆØ²Ø´"
        
    update_personality(user_id, personality)
    
    return (
        f"ğŸ§  **Ú¯Ø²Ø§Ø±Ø´ ØªØ­Ù„ÛŒÙ„ Ø´Ø®ØµÛŒØª Ú©Ø§Ø±Ø¨Ø± {user_id}:**\n\n"
        f"ØªÛŒÙ¾ Ø´Ø®ØµÛŒØªÛŒ: **{personality}**\n"
        f"Ø¨Ø± Ø§Ø³Ø§Ø³ {len(history.splitlines())} Ù¾ÛŒØ§Ù… Ø¢Ø®Ø±ØŒ Ø§ÛŒÙ† Ú©Ø§Ø±Ø¨Ø±:\n"
        f"ğŸ”¹ Ø¨Ù‡ Ø¯Ù†Ø¨Ø§Ù„ Ø³ÙˆØ¯Ø¢ÙˆØ±ÛŒ Ø³Ø±ÛŒØ¹ Ø§Ø³Øª.\n"
        f"ğŸ”¹ Ø¨Ù‡ Ø§Ù…Ù†ÛŒØª Ùˆ Ø­Ø±ÛŒÙ… Ø®ØµÙˆØµÛŒ Ø§Ù‡Ù…ÛŒØª Ù…ÛŒâ€ŒØ¯Ù‡Ø¯.\n"
        f"ğŸ”¹ Ø§Ø² Ù„Ø­Ù† Ù…Ø­ØªØ±Ù…Ø§Ù†Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."
    )
